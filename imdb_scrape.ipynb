{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c0b0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a881ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape the data \n",
    "\n",
    "def scrape_imdb_top_250(url, dest, count):\n",
    "    url = url # define url for top 250 \n",
    "    response = requests.get(url) # define response \n",
    "    top_soup = BeautifulSoup(response.text, 'html.parser') # parse the response \n",
    "\n",
    "\n",
    "    movies = top_soup.select('td.titleColumn') # get the title of a film \n",
    "    ratings = [b.attrs.get('data-value')  \n",
    "            for b in top_soup.select('td.posterColumn span[name=ir]')] # get the ratings\n",
    "    links = [a.attrs.get('href') for a in top_soup.select('td.titleColumn a')] # get the likns for futher sscraping\n",
    "\n",
    "    # list for storing data \n",
    "    top_list = []\n",
    "    # convert each movie title to string \n",
    "    for index in range(0, len(movies)):\n",
    "        movie_string = movies[index].get_text() \n",
    "        movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "        movie_title = movie[len(str(index))+1:-7]\n",
    "\n",
    "        # capture the scaraped items     \n",
    "        data = {'movie_title': movie_title,\n",
    "               'rating': ratings[index],\n",
    "               \"link\": links[index]}\n",
    "\n",
    "        # add data to list \n",
    "        top_list.append(data)\n",
    "\n",
    "    # convert to df \n",
    "    df1 = pd.DataFrame(top_list)\n",
    "\n",
    "    # get the top 20 films \n",
    "    df1 = df1.head(count)\n",
    "\n",
    "    # convert reviews to numeric \n",
    "    df1['rating'] = pd.to_numeric(df1['rating'])\n",
    "\n",
    "\n",
    "    ### get the number of oscars \n",
    "\n",
    "    # creat list for scraped data \n",
    "    oscar_list = []\n",
    "\n",
    "    for i in df1['link']:\n",
    "        url = 'http://www.imdb.com' + i\n",
    "        response = requests.get(url) # define response \n",
    "        oscar_soup = BeautifulSoup(response.text, 'html.parser') # parse the response\n",
    "    \n",
    "    # get the oscars text \n",
    "        oscar = oscar_soup.find_all('a', class_ = \n",
    "                  'ipc-metadata-list-item__label ipc-metadata-list-item__label--link')[2].text\n",
    "    # get the alternative oscars text     \n",
    "        oscar_alt = oscar_soup.find_all('a', class_ = \n",
    "                  'ipc-metadata-list-item__label ipc-metadata-list-item__label--link')[4].text\n",
    "# NOTE that for some of the titles, the oscar count comes from a different position. To account for that, we scrape both positions and then join the results\n",
    "        # capture the scaraped items  \n",
    "        data = {'oscars': oscar,\n",
    "               'oscars_alt': oscar_alt} \n",
    "        # add data to list  \n",
    "        oscar_list.append(data)\n",
    "\n",
    "    # convert to dataframe \n",
    "    df2 = pd.DataFrame(oscar_list)\n",
    "\n",
    "    # formatting \n",
    "    df2['oscars'] = df2['oscars'].str.replace(\"[^0-9]+\", \"\")\n",
    "    df2['oscars_alt'] = df2['oscars_alt'].str.replace(\"[^0-9]+\", \"\")\n",
    "    df2['oscars'] = pd.to_numeric(df2['oscars'])\n",
    "    df2['oscars_alt'] = pd.to_numeric(df2['oscars_alt'])\n",
    "    df2['oscars'] = df2['oscars'].fillna(df2['oscars_alt'])\n",
    "    df2['oscars'] = df2['oscars'].fillna(0) \n",
    "    df2 = df2.drop(['oscars_alt'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    ### get the review count\n",
    "\n",
    "    reviews_list = []\n",
    "\n",
    "    for i in df1['link']:\n",
    "        url = 'http://www.imdb.com' + i + 'ratings'\n",
    "        response = requests.get(url) # define response \n",
    "        review_soup = BeautifulSoup(response.text, 'html.parser') # parse the response\n",
    "    # get the oscars text \n",
    "        rating = review_soup.find_all('div', class_ = 'smallcell')[0].text\n",
    "\n",
    "    # create list data instance \n",
    "        data = {'ratings': rating}\n",
    "\n",
    "    # append the list     \n",
    "        reviews_list.append(data)\n",
    "\n",
    "    # convert to dataframe \n",
    "    df3 = pd.DataFrame(reviews_list)\n",
    "\n",
    "    # clean the reviews \n",
    "    df3['ratings'] = df3['ratings'].str.replace(\"[^0-9]+\", \"\")\n",
    "\n",
    "    # format as numeric \n",
    "    df3['ratings'] = pd.to_numeric(df3['ratings'])\n",
    "\n",
    "    # merge data together \n",
    "    imdb_df = pd.concat([df1, df2, df3], axis=1)\n",
    "\n",
    "    # rename columns \n",
    "    imdb_df = imdb_df.rename(columns={'movie_title': 'movie_title',\n",
    "                                          'ratings': 'num_of_ratings',\n",
    "                                          'rating': 'avg_rating', \n",
    "                                          'oscars': 'num_of_oscars', \n",
    "                                          'link': 'link'})\n",
    "\n",
    "    # write data to csv\n",
    "    imdb_df.to_csv(dest + 'imdb_scrape.csv')\n",
    "    \n",
    "    return imdb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8a30e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/gpzy0r6d60n6wyl8cf3n_vz40000gn/T/ipykernel_2983/2289055833.py:67: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df2['oscars'] = df2['oscars'].str.replace(\"[^0-9]+\", \"\")\n",
      "/var/folders/1y/gpzy0r6d60n6wyl8cf3n_vz40000gn/T/ipykernel_2983/2289055833.py:68: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df2['oscars_alt'] = df2['oscars_alt'].str.replace(\"[^0-9]+\", \"\")\n",
      "/var/folders/1y/gpzy0r6d60n6wyl8cf3n_vz40000gn/T/ipykernel_2983/2289055833.py:98: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df3['ratings'] = df3['ratings'].str.replace(\"[^0-9]+\", \"\")\n"
     ]
    }
   ],
   "source": [
    "# scrape the data \n",
    "\n",
    "# define the page to scrape \n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "# define the folder for saving the data \n",
    "destination = '/Users/steve_j/Documents/work/app/'\n",
    "# define the number of titles to scarape\n",
    "count = 20 \n",
    "\n",
    "# call the function \n",
    "imdb_df = scrape_imdb_top_250(url, destination, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
